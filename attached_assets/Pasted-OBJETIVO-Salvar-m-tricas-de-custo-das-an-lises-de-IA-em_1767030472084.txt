OBJETIVO: Salvar métricas de custo das análises de IA em banco de dados para criar histórico persistente e gerar relatórios de economia, custos e ROI do sistema.

CONTEXTO: Atualmente as métricas (totalCalls, estimatedCost, etc) são armazenadas em memória e resetam ao reiniciar o servidor. Vamos persistir em banco para análises de longo prazo.

ARQUIVOS A MODIFICAR:
1. db/schema.ts (adicionar tabela)
2. server/services/ai-service-gpt4o-mini.ts (salvar métricas)
3. server/storage.ts (adicionar métodos)
4. server/routes.ts (adicionar rota de relatório)

PASSO 1: ADICIONAR TABELA NO SCHEMA

No arquivo db/schema.ts, adicione a nova tabela ANTES de `export const insertUserSchema`:
```typescript
// Tabela de métricas de custo de IA
export const aiCostMetrics = pgTable("ai_cost_metrics", {
  id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
  timestamp: timestamp("timestamp").notNull().defaultNow(),
  
  // Identificação
  patientId: varchar("patient_id"),
  leito: text("leito"),
  operation: text("operation").notNull(), // 'clinical_analysis', 'batch_analysis'
  
  // Modelo usado
  model: text("model").notNull().default("gpt-4o-mini"),
  provider: text("provider").notNull().default("openai"),
  
  // Métricas de uso
  tokensUsed: integer("tokens_used").notNull().default(0),
  tokensPrompt: integer("tokens_prompt").notNull().default(0),
  tokensCompletion: integer("tokens_completion").notNull().default(0),
  
  // Custo
  estimatedCost: integer("estimated_cost_cents").notNull().default(0), // Em centavos
  
  // Cache
  cacheHit: boolean("cache_hit").notNull().default(false),
  cacheSource: text("cache_source"), // 'intelligent_cache', 'database', null
  
  // Performance
  durationMs: integer("duration_ms").notNull().default(0),
  
  // Resultado
  alertLevel: text("alert_level"), // 'VERMELHO', 'AMARELO', 'VERDE'
  success: boolean("success").notNull().default(true),
  errorMessage: text("error_message"),
});

export const insertAICostMetricSchema = createInsertSchema(aiCostMetrics).omit({
  id: true,
  timestamp: true,
});

export type InsertAICostMetric = z.infer<typeof insertAICostMetricSchema>;
export type AICostMetric = typeof aiCostMetrics.$inferSelect;
```

PASSO 2: FAZER PUSH DO SCHEMA

Execute no terminal:
```bash
npm run db:push
```

Confirme quando perguntado.

PASSO 3: ADICIONAR MÉTODOS NO STORAGE

No arquivo server/storage.ts, adicione na interface IStorage:
```typescript
export interface IStorage {
  // ... métodos existentes ...

  // AI Cost Metrics
  createAICostMetric(metric: Omit<InsertAICostMetric, 'id' | 'timestamp'>): Promise<AICostMetric>;
  getAICostMetricsSummary(days?: number): Promise<{
    totalCalls: number;
    totalCost: number;
    cacheHitRate: number;
    avgDuration: number;
    byModel: Record<string, { calls: number; cost: number }>;
    byDay: Array<{ date: string; calls: number; cost: number; cacheHits: number }>;
  }>;
}
```

No arquivo server/repositories/postgres-storage.ts, adicione os métodos:
```typescript
async createAICostMetric(metric: Omit<InsertAICostMetric, 'id' | 'timestamp'>): Promise<AICostMetric> {
  try {
    const [created] = await this.db.insert(aiCostMetrics).values(metric).returning();
    return created;
  } catch (error) {
    logger.error('[Storage] Error creating AI cost metric:', error);
    throw error;
  }
}

async getAICostMetricsSummary(days: number = 30): Promise<{
  totalCalls: number;
  totalCost: number;
  cacheHitRate: number;
  avgDuration: number;
  byModel: Record<string, { calls: number; cost: number }>;
  byDay: Array<{ date: string; calls: number; cost: number; cacheHits: number }>;
}> {
  try {
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - days);

    const metrics = await this.db
      .select()
      .from(aiCostMetrics)
      .where(sql`${aiCostMetrics.timestamp} >= ${cutoffDate}`);

    const totalCalls = metrics.length;
    const totalCost = metrics.reduce((sum, m) => sum + m.estimatedCost, 0) / 100; // Centavos para reais
    const cacheHits = metrics.filter(m => m.cacheHit).length;
    const cacheHitRate = totalCalls > 0 ? (cacheHits / totalCalls) * 100 : 0;
    const avgDuration = totalCalls > 0 
      ? metrics.reduce((sum, m) => sum + m.durationMs, 0) / totalCalls 
      : 0;

    // Agrupa por modelo
    const byModel: Record<string, { calls: number; cost: number }> = {};
    for (const metric of metrics) {
      if (!byModel[metric.model]) {
        byModel[metric.model] = { calls: 0, cost: 0 };
      }
      byModel[metric.model].calls++;
      byModel[metric.model].cost += metric.estimatedCost / 100;
    }

    // Agrupa por dia
    const byDayMap: Record<string, { calls: number; cost: number; cacheHits: number }> = {};
    for (const metric of metrics) {
      const date = metric.timestamp.toISOString().split('T')[0];
      if (!byDayMap[date]) {
        byDayMap[date] = { calls: 0, cost: 0, cacheHits: 0 };
      }
      byDayMap[date].calls++;
      byDayMap[date].cost += metric.estimatedCost / 100;
      if (metric.cacheHit) {
        byDayMap[date].cacheHits++;
      }
    }

    const byDay = Object.entries(byDayMap)
      .map(([date, data]) => ({ date, ...data }))
      .sort((a, b) => a.date.localeCompare(b.date));

    return {
      totalCalls,
      totalCost,
      cacheHitRate: Math.round(cacheHitRate * 100) / 100,
      avgDuration: Math.round(avgDuration),
      byModel,
      byDay
    };
  } catch (error) {
    logger.error('[Storage] Error getting AI cost metrics summary:', error);
    throw error;
  }
}
```

Adicione o import:
```typescript
import { aiCostMetrics } from "@shared/schema";
```

PASSO 4: MODIFICAR AI SERVICE PARA SALVAR MÉTRICAS

No arquivo server/services/ai-service-gpt4o-mini.ts, modifique o método performClinicalAnalysis:

Localize a linha onde chama `this.callGPT4oMiniOptimized(patient)` e envolva com tracking:
```typescript
async performClinicalAnalysis(
  patient: PatientData,
  options?: {
    useCache?: boolean;
    forceRefresh?: boolean;
  }
): Promise<PatientClinicalInsights> {
  const useCache = options?.useCache !== false;
  const forceRefresh = options?.forceRefresh || false;
  const startTime = Date.now();

  this.metrics.totalCalls++;

  // 1. Gera chave e hash de conteúdo para cache
  const cacheKey = this.generateCacheKey(patient);
  const contentHash = this.generateContentHash(patient);

  // 2. Tenta buscar do cache
  if (useCache && !forceRefresh) {
    const cached = await intelligentCache.get<PatientClinicalInsights>(
      cacheKey,
      contentHash
    );
    
    if (cached) {
      this.metrics.cachedCalls++;
      this.metrics.tokensSaved += 3500;
      this.metrics.estimatedSavings += 0.03;
      
      // Salva métrica de cache hit
      await this.saveMetric({
        patientId: patient.id || null,
        leito: patient.leito || null,
        operation: 'clinical_analysis',
        model: MODEL,
        provider: 'openai',
        tokensUsed: 0,
        tokensPrompt: 0,
        tokensCompletion: 0,
        estimatedCost: 0, // Em centavos
        cacheHit: true,
        cacheSource: 'intelligent_cache',
        durationMs: Date.now() - startTime,
        alertLevel: cached.nivel_alerta,
        success: true,
        errorMessage: null
      });
      
      console.log(`[GPT-4o-mini] ✅ Cache HIT: ${patient.leito}`);
      return cached;
    }
  }

  // 3. Cache miss - fazer chamada à API
  this.metrics.actualAPICalls++;

  try {
    const insights = await this.callGPT4oMiniOptimized(patient);

    // 4. Armazena no cache
    if (useCache) {
      const criticality = insights.nivel_alerta === 'VERMELHO' ? 'critical' : 
                         insights.nivel_alerta === 'AMARELO' ? 'high' : 'medium';
      await intelligentCache.set(cacheKey, insights, {
        contentHash,
        ttlMinutes: this.calculateTTL(insights.nivel_alerta),
        criticality
      });
    }

    // 5. Salva métrica de API call
    const duration = Date.now() - startTime;
    await this.saveMetric({
      patientId: patient.id || null,
      leito: patient.leito || null,
      operation: 'clinical_analysis',
      model: MODEL,
      provider: 'openai',
      tokensUsed: 3500, // Estimado
      tokensPrompt: 2500,
      tokensCompletion: 1000,
      estimatedCost: 3, // R$ 0.03 = 3 centavos
      cacheHit: false,
      cacheSource: null,
      durationMs: duration,
      alertLevel: insights.nivel_alerta,
      success: true,
      errorMessage: null
    });

    // 6. Atualiza métricas em memória
    this.updateMetrics(3500, 0.03);

    console.log(`[GPT-4o-mini] ✅ Análise concluída: ${patient.leito} - R$ 0.03`);
    return insights;

  } catch (error) {
    // Salva métrica de erro
    await this.saveMetric({
      patientId: patient.id || null,
      leito: patient.leito || null,
      operation: 'clinical_analysis',
      model: MODEL,
      provider: 'openai',
      tokensUsed: 0,
      tokensPrompt: 0,
      tokensCompletion: 0,
      estimatedCost: 0,
      cacheHit: false,
      cacheSource: null,
      durationMs: Date.now() - startTime,
      alertLevel: null,
      success: false,
      errorMessage: error instanceof Error ? error.message : String(error)
    });

    console.error('[GPT-4o-mini] Erro na análise:', error);
    throw error;
  }
}

/**
 * Salva métrica no banco de dados
 */
private async saveMetric(metric: Omit<InsertAICostMetric, 'id' | 'timestamp'>): Promise<void> {
  try {
    const { storage } = await import('../storage');
    await storage.createAICostMetric(metric);
  } catch (error) {
    // Não falha se métricas não salvarem
    console.warn('[GPT-4o-mini] Falha ao salvar métrica:', error);
  }
}
```

Adicione o import no topo:
```typescript
import type { InsertAICostMetric } from '@shared/schema';
```

PASSO 5: ADICIONAR ROTA DE RELATÓRIO

No arquivo server/routes.ts, adicione nova rota (pode ser após as rotas de IA):
```typescript
// AI Cost Metrics & Reports (admin only)
app.get("/api/admin/ai-costs", 
  authMiddleware,
  requireRole('admin'),
  asyncHandler(async (req, res) => {
    const days = parseInt(req.query.days as string) || 30;
    const summary = await storage.getAICostMetricsSummary(days);
    
    res.json({
      period: `${days} dias`,
      summary,
      insights: {
        totalCostFormatted: `R$ ${summary.totalCost.toFixed(2)}`,
        avgCostPerCall: summary.totalCalls > 0 
          ? `R$ ${(summary.totalCost / summary.totalCalls).toFixed(4)}`
          : 'R$ 0.00',
        savingsFromCache: summary.totalCalls > 0
          ? `R$ ${((summary.totalCalls * 0.03) - summary.totalCost).toFixed(2)}`
          : 'R$ 0.00',
        roi: summary.cacheHitRate > 70 
          ? 'Excelente economia com cache'
          : summary.cacheHitRate > 50
            ? 'Boa economia com cache'
            : 'Cache precisa otimização'
      }
    });
  })
);
```

VALIDAÇÃO APÓS APLICAR:
1. `npm run db:push` executado com sucesso
2. Tabela ai_cost_metrics criada
3. Servidor reinicia sem erros
4. Análise de paciente salva métrica automaticamente
5. GET /api/admin/ai-costs retorna relatório

TESTAR RELATÓRIO:
```bash
curl http://localhost:5000/api/admin/ai-costs?days=7 \
  -H "Authorization: Bearer SEU_TOKEN"
```

Resposta esperada:
```json
{
  "period": "7 dias",
  "summary": {
    "totalCalls": 156,
    "totalCost": 2.34,
    "cacheHitRate": 78.85,
    "avgDuration": 1234,
    "byModel": {
      "gpt-4o-mini": { "calls": 156, "cost": 2.34 }
    },
    "byDay": [
      { "date": "2024-12-23", "calls": 23, "cost": 0.45, "cacheHits": 18 },
      ...
    ]
  },
  "insights": {
    "totalCostFormatted": "R$ 2.34",
    "avgCostPerCall": "R$ 0.0150",
    "savingsFromCache": "R$ 2.34",
    "roi": "Excelente economia com cache"
  }
}
```

IMPORTANTE:
- Métricas são salvas SEMPRE (cache hit ou miss)
- Custos em centavos no banco (precisão)
- NÃO bloqueia se salvar métrica falhar
- Relatórios mostram ROI do sistema
- Performance tracking incluído

CHECKLIST DE SUCESSO:
☐ Tabela aiCostMetrics adicionada no schema.ts
☐ npm run db:push executado
☐ Métodos de storage implementados
☐ Import de aiCostMetrics adicionado
☐ performClinicalAnalysis modificado
☐ saveMetric implementado
☐ Rota /api/admin/ai-costs adicionada
☐ Servidor reinicia sem erros
☐ Análises salvam métricas automaticamente
☐ Relatório retorna dados corretos